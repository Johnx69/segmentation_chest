[
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "modules",
        "importPath": "models.base",
        "description": "models.base",
        "isExtraImport": true,
        "detail": "models.base",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "importPath": "models.base",
        "description": "models.base",
        "isExtraImport": true,
        "detail": "models.base",
        "documentation": {}
    },
    {
        "label": "SegmentationHead",
        "importPath": "models.base",
        "description": "models.base",
        "isExtraImport": true,
        "detail": "models.base",
        "documentation": {}
    },
    {
        "label": "ClassificationHead",
        "importPath": "models.base",
        "description": "models.base",
        "isExtraImport": true,
        "detail": "models.base",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "get_encoder",
        "importPath": "models.encoders",
        "description": "models.encoders",
        "isExtraImport": true,
        "detail": "models.encoders",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "pretrained_settings",
        "importPath": "pretrainedmodels.models.torchvision_models",
        "description": "pretrainedmodels.models.torchvision_models",
        "isExtraImport": true,
        "detail": "pretrainedmodels.models.torchvision_models",
        "documentation": {}
    },
    {
        "label": "pretrained_settings",
        "importPath": "pretrainedmodels.models.torchvision_models",
        "description": "pretrainedmodels.models.torchvision_models",
        "isExtraImport": true,
        "detail": "pretrainedmodels.models.torchvision_models",
        "documentation": {}
    },
    {
        "label": "DenseNet",
        "importPath": "torchvision.models.densenet",
        "description": "torchvision.models.densenet",
        "isExtraImport": true,
        "detail": "torchvision.models.densenet",
        "documentation": {}
    },
    {
        "label": "InceptionV4",
        "importPath": "pretrainedmodels.models.inceptionv4",
        "description": "pretrainedmodels.models.inceptionv4",
        "isExtraImport": true,
        "detail": "pretrainedmodels.models.inceptionv4",
        "documentation": {}
    },
    {
        "label": "BasicConv2d",
        "importPath": "pretrainedmodels.models.inceptionv4",
        "description": "pretrainedmodels.models.inceptionv4",
        "isExtraImport": true,
        "detail": "pretrainedmodels.models.inceptionv4",
        "documentation": {}
    },
    {
        "label": "pretrained_settings",
        "importPath": "pretrainedmodels.models.inceptionv4",
        "description": "pretrainedmodels.models.inceptionv4",
        "isExtraImport": true,
        "detail": "pretrainedmodels.models.inceptionv4",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "DropPath",
        "importPath": "timm.layers",
        "description": "timm.layers",
        "isExtraImport": true,
        "detail": "timm.layers",
        "documentation": {}
    },
    {
        "label": "to_2tuple",
        "importPath": "timm.layers",
        "description": "timm.layers",
        "isExtraImport": true,
        "detail": "timm.layers",
        "documentation": {}
    },
    {
        "label": "trunc_normal_",
        "importPath": "timm.layers",
        "description": "timm.layers",
        "isExtraImport": true,
        "detail": "timm.layers",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "ResNet",
        "importPath": "torchvision.models.resnet",
        "description": "torchvision.models.resnet",
        "isExtraImport": true,
        "detail": "torchvision.models.resnet",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "importPath": "torchvision.models.resnet",
        "description": "torchvision.models.resnet",
        "isExtraImport": true,
        "detail": "torchvision.models.resnet",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "importPath": "torchvision.models.resnet",
        "description": "torchvision.models.resnet",
        "isExtraImport": true,
        "detail": "torchvision.models.resnet",
        "documentation": {}
    },
    {
        "label": "EfficientNet",
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "isExtraImport": true,
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "decode_arch_def",
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "isExtraImport": true,
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "round_channels",
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "isExtraImport": true,
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "default_cfgs",
        "importPath": "timm.models.efficientnet",
        "description": "timm.models.efficientnet",
        "isExtraImport": true,
        "detail": "timm.models.efficientnet",
        "documentation": {}
    },
    {
        "label": "Swish",
        "importPath": "timm.layers.activations",
        "description": "timm.layers.activations",
        "isExtraImport": true,
        "detail": "timm.layers.activations",
        "documentation": {}
    },
    {
        "label": "timm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "timm",
        "description": "timm",
        "detail": "timm",
        "documentation": {}
    },
    {
        "label": "imgaug.augmenters",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "imgaug.augmenters",
        "description": "imgaug.augmenters",
        "detail": "imgaug.augmenters",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "torchvision.transforms",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "AverageMeter",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "calculate_overlap_metrics",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "AverageMeter",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "calculate_overlap_metrics",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "calculate_overlap_metrics_post",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "gc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gc",
        "description": "gc",
        "detail": "gc",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "recall_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "recall_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "Covid",
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "isExtraImport": true,
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "Covid",
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "isExtraImport": true,
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "models",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "models",
        "description": "models",
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "noise_remove",
        "importPath": "utils.post_processing",
        "description": "utils.post_processing",
        "isExtraImport": true,
        "detail": "utils.post_processing",
        "documentation": {}
    },
    {
        "label": "post_processing",
        "importPath": "utils.post_processing",
        "description": "utils.post_processing",
        "isExtraImport": true,
        "detail": "utils.post_processing",
        "documentation": {}
    },
    {
        "label": "SegmentationHead",
        "kind": 6,
        "importPath": "models.base.heads",
        "description": "models.base.heads",
        "peekOfCode": "class SegmentationHead(nn.Sequential):\n    def __init__(\n        self, in_channels, out_channels, kernel_size=3, activation=None, upsampling=1\n    ):\n        conv2d = nn.Conv2d(\n            in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2\n        )\n        upsampling = (\n            nn.UpsamplingBilinear2d(scale_factor=upsampling)\n            if upsampling > 1",
        "detail": "models.base.heads",
        "documentation": {}
    },
    {
        "label": "ClassificationHead",
        "kind": 6,
        "importPath": "models.base.heads",
        "description": "models.base.heads",
        "peekOfCode": "class ClassificationHead(nn.Sequential):\n    def __init__(\n        self, in_channels, classes, pooling=\"avg\", dropout=0.2, activation=None\n    ):\n        if pooling not in (\"max\", \"avg\"):\n            raise ValueError(\n                \"Pooling should be one of ('max', 'avg'), got {}.\".format(pooling)\n            )\n        pool = nn.AdaptiveAvgPool2d(1) if pooling == \"avg\" else nn.AdaptiveMaxPool2d(1)\n        flatten = nn.Flatten()",
        "detail": "models.base.heads",
        "documentation": {}
    },
    {
        "label": "initialize_decoder",
        "kind": 2,
        "importPath": "models.base.initialization",
        "description": "models.base.initialization",
        "peekOfCode": "def initialize_decoder(module):\n    for m in module.modules():\n        if isinstance(m, nn.Conv2d):\n            nn.init.kaiming_uniform_(m.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            nn.init.constant_(m.weight, 1)\n            nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.Linear):",
        "detail": "models.base.initialization",
        "documentation": {}
    },
    {
        "label": "initialize_head",
        "kind": 2,
        "importPath": "models.base.initialization",
        "description": "models.base.initialization",
        "peekOfCode": "def initialize_head(module):\n    for m in module.modules():\n        if isinstance(m, (nn.Linear, nn.Conv2d)):\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)",
        "detail": "models.base.initialization",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "kind": 6,
        "importPath": "models.base.model",
        "description": "models.base.model",
        "peekOfCode": "class SegmentationModel(torch.nn.Module):\n    def initialize(self):\n        init.initialize_decoder(self.decoder_1)\n        init.initialize_head(self.segmentation_head_1)\n        init.initialize_decoder(self.decoder_1)\n        init.initialize_head(self.segmentation_head_1)\n        if self.classification_head is not None:\n            init.initialize_head(self.classification_head)\n    def check_input_shape(self, x):\n        h, w = x.shape[-2:]",
        "detail": "models.base.model",
        "documentation": {}
    },
    {
        "label": "Conv2dReLU",
        "kind": 6,
        "importPath": "models.base.modules",
        "description": "models.base.modules",
        "peekOfCode": "class Conv2dReLU(nn.Sequential):\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel_size,\n        padding=0,\n        stride=1,\n        use_batchnorm=True,\n    ):",
        "detail": "models.base.modules",
        "documentation": {}
    },
    {
        "label": "SCSEModule",
        "kind": 6,
        "importPath": "models.base.modules",
        "description": "models.base.modules",
        "peekOfCode": "class SCSEModule(nn.Module):\n    def __init__(self, in_channels, reduction=16):\n        super().__init__()\n        self.cSE = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(in_channels, in_channels // reduction, 1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels // reduction, in_channels, 1),\n            nn.Sigmoid(),\n        )",
        "detail": "models.base.modules",
        "documentation": {}
    },
    {
        "label": "ArgMax",
        "kind": 6,
        "importPath": "models.base.modules",
        "description": "models.base.modules",
        "peekOfCode": "class ArgMax(nn.Module):\n    def __init__(self, dim=None):\n        super().__init__()\n        self.dim = dim\n    def forward(self, x):\n        return torch.argmax(x, dim=self.dim)\nclass Clamp(nn.Module):\n    def __init__(self, min=0, max=1):\n        super().__init__()\n        self.min, self.max = min, max",
        "detail": "models.base.modules",
        "documentation": {}
    },
    {
        "label": "Clamp",
        "kind": 6,
        "importPath": "models.base.modules",
        "description": "models.base.modules",
        "peekOfCode": "class Clamp(nn.Module):\n    def __init__(self, min=0, max=1):\n        super().__init__()\n        self.min, self.max = min, max\n    def forward(self, x):\n        return torch.clamp(x, self.min, self.max)\nclass Activation(nn.Module):\n    def __init__(self, name, **params):\n        super().__init__()\n        if name is None or name == \"identity\":",
        "detail": "models.base.modules",
        "documentation": {}
    },
    {
        "label": "Activation",
        "kind": 6,
        "importPath": "models.base.modules",
        "description": "models.base.modules",
        "peekOfCode": "class Activation(nn.Module):\n    def __init__(self, name, **params):\n        super().__init__()\n        if name is None or name == \"identity\":\n            self.activation = nn.Identity(**params)\n        elif name == \"sigmoid\":\n            self.activation = nn.Sigmoid()\n        elif name == \"softmax2d\":\n            self.activation = nn.Softmax(dim=1, **params)\n        elif name == \"softmax\":",
        "detail": "models.base.modules",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "models.base.modules",
        "description": "models.base.modules",
        "peekOfCode": "class Attention(nn.Module):\n    def __init__(self, name, **params):\n        super().__init__()\n        if name is None:\n            self.attention = nn.Identity(**params)\n        elif name == \"scse\":\n            self.attention = SCSEModule(**params)\n        else:\n            raise ValueError(\"Attention {} is not implemented\".format(name))\n    def forward(self, x):",
        "detail": "models.base.modules",
        "documentation": {}
    },
    {
        "label": "DecoderBlock",
        "kind": 6,
        "importPath": "models.decoders.unet.decoder",
        "description": "models.decoders.unet.decoder",
        "peekOfCode": "class DecoderBlock(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        skip_channels,\n        out_channels,\n        use_batchnorm=True,\n        attention_type=None,\n    ):\n        super().__init__()",
        "detail": "models.decoders.unet.decoder",
        "documentation": {}
    },
    {
        "label": "CenterBlock",
        "kind": 6,
        "importPath": "models.decoders.unet.decoder",
        "description": "models.decoders.unet.decoder",
        "peekOfCode": "class CenterBlock(nn.Sequential):\n    def __init__(self, in_channels, out_channels, use_batchnorm=True):\n        conv1 = md.Conv2dReLU(\n            in_channels,\n            out_channels,\n            kernel_size=3,\n            padding=1,\n            use_batchnorm=use_batchnorm,\n        )\n        conv2 = md.Conv2dReLU(",
        "detail": "models.decoders.unet.decoder",
        "documentation": {}
    },
    {
        "label": "UnetDecoder",
        "kind": 6,
        "importPath": "models.decoders.unet.decoder",
        "description": "models.decoders.unet.decoder",
        "peekOfCode": "class UnetDecoder(nn.Module):\n    def __init__(\n        self,\n        encoder_channels,\n        decoder_channels,\n        n_blocks=5,\n        use_batchnorm=True,\n        attention_type=None,\n        center=False,\n    ):",
        "detail": "models.decoders.unet.decoder",
        "documentation": {}
    },
    {
        "label": "Unet",
        "kind": 6,
        "importPath": "models.decoders.unet.model",
        "description": "models.decoders.unet.model",
        "peekOfCode": "class Unet(SegmentationModel):\n    \"\"\"Unet_ is a fully convolution neural network for image semantic segmentation. Consist of *encoder*\n    and *decoder* parts connected with *skip connections*. Encoder extract features of different spatial\n    resolution (skip connections) which are used by decoder to define accurate segmentation mask. Use *concatenation*\n    for fusing decoder blocks with skip connections.\n    Args:\n        encoder_name: Name of the classification model that will be used as an encoder (a.k.a backbone)\n            to extract features of different spatial resolution\n        encoder_depth: A number of stages used in encoder in range [3, 5]. Each stage generate features\n            two times smaller in spatial dimensions than previous one (e.g. for depth 0 we will have features",
        "detail": "models.decoders.unet.model",
        "documentation": {}
    },
    {
        "label": "EncoderMixin",
        "kind": 6,
        "importPath": "models.encoders._base",
        "description": "models.encoders._base",
        "peekOfCode": "class EncoderMixin:\n    \"\"\"Add encoder functionality such as:\n    - output channels specification of feature tensors (produced by encoder)\n    - patching first convolution for arbitrary input channels\n    \"\"\"\n    _output_stride = 32\n    @property\n    def out_channels(self):\n        \"\"\"Return channels dimensions for each tensor of forward output of encoder\"\"\"\n        return self._out_channels[: self._depth + 1]",
        "detail": "models.encoders._base",
        "documentation": {}
    },
    {
        "label": "preprocess_input",
        "kind": 2,
        "importPath": "models.encoders._preprocessing",
        "description": "models.encoders._preprocessing",
        "peekOfCode": "def preprocess_input(\n    x, mean=None, std=None, input_space=\"RGB\", input_range=None, **kwargs\n):\n    if input_space == \"BGR\":\n        x = x[..., ::-1].copy()\n    if input_range is not None:\n        if x.max() > 1 and input_range[1] == 1:\n            x = x / 255.0\n    if mean is not None:\n        mean = np.array(mean)",
        "detail": "models.encoders._preprocessing",
        "documentation": {}
    },
    {
        "label": "patch_first_conv",
        "kind": 2,
        "importPath": "models.encoders._utils",
        "description": "models.encoders._utils",
        "peekOfCode": "def patch_first_conv(model, new_in_channels, default_in_channels=3, pretrained=True):\n    \"\"\"Change first convolution layer input channels.\n    In case:\n        in_channels == 1 or in_channels == 2 -> reuse original weights\n        in_channels > 3 -> make random kaiming normal initialization\n    \"\"\"\n    # get first conv\n    for module in model.modules():\n        if isinstance(module, nn.Conv2d) and module.in_channels == default_in_channels:\n            break",
        "detail": "models.encoders._utils",
        "documentation": {}
    },
    {
        "label": "replace_strides_with_dilation",
        "kind": 2,
        "importPath": "models.encoders._utils",
        "description": "models.encoders._utils",
        "peekOfCode": "def replace_strides_with_dilation(module, dilation_rate):\n    \"\"\"Patch Conv2d modules replacing strides with dilation\"\"\"\n    for mod in module.modules():\n        if isinstance(mod, nn.Conv2d):\n            mod.stride = (1, 1)\n            mod.dilation = (dilation_rate, dilation_rate)\n            kh, kw = mod.kernel_size\n            mod.padding = ((kh // 2) * dilation_rate, (kh // 2) * dilation_rate)\n            # Kostyl for EfficientNet\n            if hasattr(mod, \"static_padding\"):",
        "detail": "models.encoders._utils",
        "documentation": {}
    },
    {
        "label": "TransitionWithSkip",
        "kind": 6,
        "importPath": "models.encoders.densenet",
        "description": "models.encoders.densenet",
        "peekOfCode": "class TransitionWithSkip(nn.Module):\n    def __init__(self, module):\n        super().__init__()\n        self.module = module\n    def forward(self, x):\n        for module in self.module:\n            x = module(x)\n            if isinstance(module, nn.ReLU):\n                skip = x\n        return x, skip",
        "detail": "models.encoders.densenet",
        "documentation": {}
    },
    {
        "label": "DenseNetEncoder",
        "kind": 6,
        "importPath": "models.encoders.densenet",
        "description": "models.encoders.densenet",
        "peekOfCode": "class DenseNetEncoder(DenseNet, EncoderMixin):\n    def __init__(self, out_channels, depth=5, **kwargs):\n        super().__init__(**kwargs)\n        self._out_channels = out_channels\n        self._depth = depth\n        self._in_channels = 3\n        del self.classifier\n    def make_dilated(self, *args, **kwargs):\n        raise ValueError(\n            \"DenseNet encoders do not support dilated mode \"",
        "detail": "models.encoders.densenet",
        "documentation": {}
    },
    {
        "label": "densenet_encoders",
        "kind": 5,
        "importPath": "models.encoders.densenet",
        "description": "models.encoders.densenet",
        "peekOfCode": "densenet_encoders = {\n    \"densenet121\": {\n        \"encoder\": DenseNetEncoder,\n        \"pretrained_settings\": pretrained_settings[\"densenet121\"],\n        \"params\": {\n            \"out_channels\": (3, 64, 256, 512, 1024, 1024),\n            \"num_init_features\": 64,\n            \"growth_rate\": 32,\n            \"block_config\": (6, 12, 24, 16),\n        },",
        "detail": "models.encoders.densenet",
        "documentation": {}
    },
    {
        "label": "InceptionV4Encoder",
        "kind": 6,
        "importPath": "models.encoders.inceptionv4",
        "description": "models.encoders.inceptionv4",
        "peekOfCode": "class InceptionV4Encoder(InceptionV4, EncoderMixin):\n    def __init__(self, stage_idxs, out_channels, depth=5, **kwargs):\n        super().__init__(**kwargs)\n        self._stage_idxs = stage_idxs\n        self._out_channels = out_channels\n        self._depth = depth\n        self._in_channels = 3\n        # correct paddings\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):",
        "detail": "models.encoders.inceptionv4",
        "documentation": {}
    },
    {
        "label": "inceptionv4_encoders",
        "kind": 5,
        "importPath": "models.encoders.inceptionv4",
        "description": "models.encoders.inceptionv4",
        "peekOfCode": "inceptionv4_encoders = {\n    \"inceptionv4\": {\n        \"encoder\": InceptionV4Encoder,\n        \"pretrained_settings\": pretrained_settings[\"inceptionv4\"],\n        \"params\": {\n            \"stage_idxs\": (3, 5, 9, 15),\n            \"out_channels\": (3, 64, 192, 384, 1024, 1536),\n            \"num_classes\": 1001,\n        },\n    }",
        "detail": "models.encoders.inceptionv4",
        "documentation": {}
    },
    {
        "label": "Mlp",
        "kind": 6,
        "importPath": "models.encoders.mix_tranformer",
        "description": "models.encoders.mix_tranformer",
        "peekOfCode": "class Mlp(nn.Module):\n    def __init__(\n        self,\n        in_features,\n        hidden_features=None,\n        out_features=None,\n        act_layer=nn.GELU,\n        drop=0.0,\n    ):\n        super().__init__()",
        "detail": "models.encoders.mix_tranformer",
        "documentation": {}
    },
    {
        "label": "Attention",
        "kind": 6,
        "importPath": "models.encoders.mix_tranformer",
        "description": "models.encoders.mix_tranformer",
        "peekOfCode": "class Attention(nn.Module):\n    def __init__(\n        self,\n        dim,\n        num_heads=8,\n        qkv_bias=False,\n        qk_scale=None,\n        attn_drop=0.0,\n        proj_drop=0.0,\n        sr_ratio=1,",
        "detail": "models.encoders.mix_tranformer",
        "documentation": {}
    },
    {
        "label": "Block",
        "kind": 6,
        "importPath": "models.encoders.mix_tranformer",
        "description": "models.encoders.mix_tranformer",
        "peekOfCode": "class Block(nn.Module):\n    def __init__(\n        self,\n        dim,\n        num_heads,\n        mlp_ratio=4.0,\n        qkv_bias=False,\n        qk_scale=None,\n        drop=0.0,\n        attn_drop=0.0,",
        "detail": "models.encoders.mix_tranformer",
        "documentation": {}
    },
    {
        "label": "OverlapPatchEmbed",
        "kind": 6,
        "importPath": "models.encoders.mix_tranformer",
        "description": "models.encoders.mix_tranformer",
        "peekOfCode": "class OverlapPatchEmbed(nn.Module):\n    \"\"\"Image to Patch Embedding\"\"\"\n    def __init__(self, img_size=224, patch_size=7, stride=4, in_chans=3, embed_dim=768):\n        super().__init__()\n        img_size = to_2tuple(img_size)\n        patch_size = to_2tuple(patch_size)\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.H, self.W = img_size[0] // patch_size[0], img_size[1] // patch_size[1]\n        self.num_patches = self.H * self.W",
        "detail": "models.encoders.mix_tranformer",
        "documentation": {}
    },
    {
        "label": "MixVisionTransformer",
        "kind": 6,
        "importPath": "models.encoders.mix_tranformer",
        "description": "models.encoders.mix_tranformer",
        "peekOfCode": "class MixVisionTransformer(nn.Module):\n    def __init__(\n        self,\n        img_size=224,\n        patch_size=16,\n        in_chans=3,\n        num_classes=1000,\n        embed_dims=[64, 128, 256, 512],\n        num_heads=[1, 2, 4, 8],\n        mlp_ratios=[4, 4, 4, 4],",
        "detail": "models.encoders.mix_tranformer",
        "documentation": {}
    },
    {
        "label": "DWConv",
        "kind": 6,
        "importPath": "models.encoders.mix_tranformer",
        "description": "models.encoders.mix_tranformer",
        "peekOfCode": "class DWConv(nn.Module):\n    def __init__(self, dim=768):\n        super(DWConv, self).__init__()\n        self.dwconv = nn.Conv2d(dim, dim, 3, 1, 1, bias=True, groups=dim)\n    def forward(self, x, H, W):\n        B, N, C = x.shape\n        x = x.transpose(1, 2).view(B, C, H, W)\n        x = self.dwconv(x)\n        x = x.flatten(2).transpose(1, 2)\n        return x",
        "detail": "models.encoders.mix_tranformer",
        "documentation": {}
    },
    {
        "label": "MixVisionTransformerEncoder",
        "kind": 6,
        "importPath": "models.encoders.mix_tranformer",
        "description": "models.encoders.mix_tranformer",
        "peekOfCode": "class MixVisionTransformerEncoder(MixVisionTransformer, EncoderMixin):\n    def __init__(self, out_channels, depth=5, **kwargs):\n        super().__init__(**kwargs)\n        self._out_channels = out_channels\n        self._depth = depth\n        self._in_channels = 3\n    def make_dilated(self, *args, **kwargs):\n        raise ValueError(\"MixVisionTransformer encoder does not support dilated mode\")\n    def set_in_channels(self, in_channels, *args, **kwargs):\n        if in_channels != 3:",
        "detail": "models.encoders.mix_tranformer",
        "documentation": {}
    },
    {
        "label": "get_pretrained_cfg",
        "kind": 2,
        "importPath": "models.encoders.mix_tranformer",
        "description": "models.encoders.mix_tranformer",
        "peekOfCode": "def get_pretrained_cfg(name):\n    return {\n        \"url\": \"https://github.com/qubvel/segmentation_models.pytorch/releases/download/v0.0.2/{}.pth\".format(\n            name\n        ),\n        \"input_space\": \"RGB\",\n        \"input_size\": [3, 224, 224],\n        \"input_range\": [0, 1],\n        \"mean\": [0.485, 0.456, 0.406],\n        \"std\": [0.229, 0.224, 0.225],",
        "detail": "models.encoders.mix_tranformer",
        "documentation": {}
    },
    {
        "label": "mix_transformer_encoders",
        "kind": 5,
        "importPath": "models.encoders.mix_tranformer",
        "description": "models.encoders.mix_tranformer",
        "peekOfCode": "mix_transformer_encoders = {\n    \"mit_b0\": {\n        \"encoder\": MixVisionTransformerEncoder,\n        \"pretrained_settings\": {\n            \"imagenet\": get_pretrained_cfg(\"mit_b0\"),\n        },\n        \"params\": dict(\n            out_channels=(3, 0, 32, 64, 160, 256),\n            patch_size=4,\n            embed_dims=[32, 64, 160, 256],",
        "detail": "models.encoders.mix_tranformer",
        "documentation": {}
    },
    {
        "label": "MobileNetV2Encoder",
        "kind": 6,
        "importPath": "models.encoders.mobilenet",
        "description": "models.encoders.mobilenet",
        "peekOfCode": "class MobileNetV2Encoder(torchvision.models.MobileNetV2, EncoderMixin):\n    def __init__(self, out_channels, depth=5, **kwargs):\n        super().__init__(**kwargs)\n        self._depth = depth\n        self._out_channels = out_channels\n        self._in_channels = 3\n        del self.classifier\n    def get_stages(self):\n        return [\n            nn.Identity(),",
        "detail": "models.encoders.mobilenet",
        "documentation": {}
    },
    {
        "label": "mobilenet_encoders",
        "kind": 5,
        "importPath": "models.encoders.mobilenet",
        "description": "models.encoders.mobilenet",
        "peekOfCode": "mobilenet_encoders = {\n    \"mobilenet_v2\": {\n        \"encoder\": MobileNetV2Encoder,\n        \"pretrained_settings\": {\n            \"imagenet\": {\n                \"mean\": [0.485, 0.456, 0.406],\n                \"std\": [0.229, 0.224, 0.225],\n                \"url\": \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\",\n                \"input_space\": \"RGB\",\n                \"input_range\": [0, 1],",
        "detail": "models.encoders.mobilenet",
        "documentation": {}
    },
    {
        "label": "ResNetEncoder",
        "kind": 6,
        "importPath": "models.encoders.resnet",
        "description": "models.encoders.resnet",
        "peekOfCode": "class ResNetEncoder(ResNet, EncoderMixin):\n    def __init__(self, out_channels, depth=5, **kwargs):\n        super().__init__(**kwargs)\n        self._depth = depth\n        self._out_channels = out_channels\n        self._in_channels = 3\n        del self.fc\n        del self.avgpool\n    def get_stages(self):\n        return [",
        "detail": "models.encoders.resnet",
        "documentation": {}
    },
    {
        "label": "new_settings",
        "kind": 5,
        "importPath": "models.encoders.resnet",
        "description": "models.encoders.resnet",
        "peekOfCode": "new_settings = {\n    \"resnet18\": {\n        \"ssl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnet18-d92f0530.pth\",  # noqa\n        \"swsl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnet18-118f1556.pth\",  # noqa\n    },\n    \"resnet50\": {\n        \"ssl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnet50-08389792.pth\",  # noqa\n        \"swsl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnet50-16a12f1b.pth\",  # noqa\n    },\n    \"resnext50_32x4d\": {",
        "detail": "models.encoders.resnet",
        "documentation": {}
    },
    {
        "label": "pretrained_settings",
        "kind": 5,
        "importPath": "models.encoders.resnet",
        "description": "models.encoders.resnet",
        "peekOfCode": "pretrained_settings = deepcopy(pretrained_settings)\nfor model_name, sources in new_settings.items():\n    if model_name not in pretrained_settings:\n        pretrained_settings[model_name] = {}\n    for source_name, source_url in sources.items():\n        pretrained_settings[model_name][source_name] = {\n            \"url\": source_url,\n            \"input_size\": [3, 224, 224],\n            \"input_range\": [0, 1],\n            \"mean\": [0.485, 0.456, 0.406],",
        "detail": "models.encoders.resnet",
        "documentation": {}
    },
    {
        "label": "resnet_encoders",
        "kind": 5,
        "importPath": "models.encoders.resnet",
        "description": "models.encoders.resnet",
        "peekOfCode": "resnet_encoders = {\n    \"resnet18\": {\n        \"encoder\": ResNetEncoder,\n        \"pretrained_settings\": pretrained_settings[\"resnet18\"],\n        \"params\": {\n            \"out_channels\": (3, 64, 64, 128, 256, 512),\n            \"block\": BasicBlock,\n            \"layers\": [2, 2, 2, 2],\n        },\n    },",
        "detail": "models.encoders.resnet",
        "documentation": {}
    },
    {
        "label": "EfficientNetBaseEncoder",
        "kind": 6,
        "importPath": "models.encoders.timm_efficientnet",
        "description": "models.encoders.timm_efficientnet",
        "peekOfCode": "class EfficientNetBaseEncoder(EfficientNet, EncoderMixin):\n    def __init__(self, stage_idxs, out_channels, depth=5, **kwargs):\n        super().__init__(**kwargs)\n        self._stage_idxs = stage_idxs\n        self._out_channels = out_channels\n        self._depth = depth\n        self._in_channels = 3\n        del self.classifier\n    def get_stages(self):\n        return [",
        "detail": "models.encoders.timm_efficientnet",
        "documentation": {}
    },
    {
        "label": "EfficientNetEncoder",
        "kind": 6,
        "importPath": "models.encoders.timm_efficientnet",
        "description": "models.encoders.timm_efficientnet",
        "peekOfCode": "class EfficientNetEncoder(EfficientNetBaseEncoder):\n    def __init__(\n        self,\n        stage_idxs,\n        out_channels,\n        depth=5,\n        channel_multiplier=1.0,\n        depth_multiplier=1.0,\n        drop_rate=0.2,\n    ):",
        "detail": "models.encoders.timm_efficientnet",
        "documentation": {}
    },
    {
        "label": "EfficientNetLiteEncoder",
        "kind": 6,
        "importPath": "models.encoders.timm_efficientnet",
        "description": "models.encoders.timm_efficientnet",
        "peekOfCode": "class EfficientNetLiteEncoder(EfficientNetBaseEncoder):\n    def __init__(\n        self,\n        stage_idxs,\n        out_channels,\n        depth=5,\n        channel_multiplier=1.0,\n        depth_multiplier=1.0,\n        drop_rate=0.2,\n    ):",
        "detail": "models.encoders.timm_efficientnet",
        "documentation": {}
    },
    {
        "label": "get_efficientnet_kwargs",
        "kind": 2,
        "importPath": "models.encoders.timm_efficientnet",
        "description": "models.encoders.timm_efficientnet",
        "peekOfCode": "def get_efficientnet_kwargs(channel_multiplier=1.0, depth_multiplier=1.0, drop_rate=0.2):\n    \"\"\"Create EfficientNet model.\n    Ref impl: https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/efficientnet_model.py\n    Paper: https://arxiv.org/abs/1905.11946\n    EfficientNet params\n    name: (channel_multiplier, depth_multiplier, resolution, dropout_rate)\n    'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n    'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n    'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n    'efficientnet-b3': (1.2, 1.4, 300, 0.3),",
        "detail": "models.encoders.timm_efficientnet",
        "documentation": {}
    },
    {
        "label": "gen_efficientnet_lite_kwargs",
        "kind": 2,
        "importPath": "models.encoders.timm_efficientnet",
        "description": "models.encoders.timm_efficientnet",
        "peekOfCode": "def gen_efficientnet_lite_kwargs(channel_multiplier=1.0, depth_multiplier=1.0, drop_rate=0.2):\n    \"\"\"EfficientNet-Lite model.\n    Ref impl: https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite\n    Paper: https://arxiv.org/abs/1905.11946\n    EfficientNet params\n    name: (channel_multiplier, depth_multiplier, resolution, dropout_rate)\n      'efficientnet-lite0': (1.0, 1.0, 224, 0.2),\n      'efficientnet-lite1': (1.0, 1.1, 240, 0.2),\n      'efficientnet-lite2': (1.1, 1.2, 260, 0.3),\n      'efficientnet-lite3': (1.2, 1.4, 280, 0.3),",
        "detail": "models.encoders.timm_efficientnet",
        "documentation": {}
    },
    {
        "label": "prepare_settings",
        "kind": 2,
        "importPath": "models.encoders.timm_efficientnet",
        "description": "models.encoders.timm_efficientnet",
        "peekOfCode": "def prepare_settings(settings):\n    return {\n        \"mean\": settings.mean,\n        \"std\": settings.std,\n        \"url\": settings.url,\n        \"input_range\": (0, 1),\n        \"input_space\": \"RGB\",\n    }\ntimm_efficientnet_encoders = {\n    \"timm-efficientnet-b0\": {",
        "detail": "models.encoders.timm_efficientnet",
        "documentation": {}
    },
    {
        "label": "timm_efficientnet_encoders",
        "kind": 5,
        "importPath": "models.encoders.timm_efficientnet",
        "description": "models.encoders.timm_efficientnet",
        "peekOfCode": "timm_efficientnet_encoders = {\n    \"timm-efficientnet-b0\": {\n        \"encoder\": EfficientNetEncoder,\n        \"pretrained_settings\": {\n            \"imagenet\": prepare_settings(default_cfgs[\"tf_efficientnet_b0\"].cfgs[\"in1k\"]),\n            \"advprop\": prepare_settings(default_cfgs[\"tf_efficientnet_b0\"].cfgs[\"ap_in1k\"]),\n            \"noisy-student\": prepare_settings(default_cfgs[\"tf_efficientnet_b0\"].cfgs[\"ns_jft_in1k\"]),\n        },\n        \"params\": {\n            \"out_channels\": (3, 32, 24, 40, 112, 320),",
        "detail": "models.encoders.timm_efficientnet",
        "documentation": {}
    },
    {
        "label": "MobileNetV3Encoder",
        "kind": 6,
        "importPath": "models.encoders.timm_mobilenetv3",
        "description": "models.encoders.timm_mobilenetv3",
        "peekOfCode": "class MobileNetV3Encoder(nn.Module, EncoderMixin):\n    def __init__(self, model_name, width_mult, depth=5, **kwargs):\n        super().__init__()\n        if \"large\" not in model_name and \"small\" not in model_name:\n            raise ValueError(\"MobileNetV3 wrong model name {}\".format(model_name))\n        self._mode = \"small\" if \"small\" in model_name else \"large\"\n        self._depth = depth\n        self._out_channels = self._get_channels(self._mode, width_mult)\n        self._in_channels = 3\n        # minimal models replace hardswish with relu",
        "detail": "models.encoders.timm_mobilenetv3",
        "documentation": {}
    },
    {
        "label": "mobilenetv3_weights",
        "kind": 5,
        "importPath": "models.encoders.timm_mobilenetv3",
        "description": "models.encoders.timm_mobilenetv3",
        "peekOfCode": "mobilenetv3_weights = {\n    \"tf_mobilenetv3_large_075\": {\n        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mobilenetv3_large_075-150ee8b0.pth\"  # noqa\n    },\n    \"tf_mobilenetv3_large_100\": {\n        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mobilenetv3_large_100-427764d5.pth\"  # noqa\n    },\n    \"tf_mobilenetv3_large_minimal_100\": {\n        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mobilenetv3_large_minimal_100-8596ae28.pth\"  # noqa\n    },",
        "detail": "models.encoders.timm_mobilenetv3",
        "documentation": {}
    },
    {
        "label": "pretrained_settings",
        "kind": 5,
        "importPath": "models.encoders.timm_mobilenetv3",
        "description": "models.encoders.timm_mobilenetv3",
        "peekOfCode": "pretrained_settings = {}\nfor model_name, sources in mobilenetv3_weights.items():\n    pretrained_settings[model_name] = {}\n    for source_name, source_url in sources.items():\n        pretrained_settings[model_name][source_name] = {\n            \"url\": source_url,\n            \"input_range\": [0, 1],\n            \"mean\": [0.485, 0.456, 0.406],\n            \"std\": [0.229, 0.224, 0.225],\n            \"input_space\": \"RGB\",",
        "detail": "models.encoders.timm_mobilenetv3",
        "documentation": {}
    },
    {
        "label": "timm_mobilenetv3_encoders",
        "kind": 5,
        "importPath": "models.encoders.timm_mobilenetv3",
        "description": "models.encoders.timm_mobilenetv3",
        "peekOfCode": "timm_mobilenetv3_encoders = {\n    \"timm-mobilenetv3_large_075\": {\n        \"encoder\": MobileNetV3Encoder,\n        \"pretrained_settings\": pretrained_settings[\"tf_mobilenetv3_large_075\"],\n        \"params\": {\"model_name\": \"tf_mobilenetv3_large_075\", \"width_mult\": 0.75},\n    },\n    \"timm-mobilenetv3_large_100\": {\n        \"encoder\": MobileNetV3Encoder,\n        \"pretrained_settings\": pretrained_settings[\"tf_mobilenetv3_large_100\"],\n        \"params\": {\"model_name\": \"tf_mobilenetv3_large_100\", \"width_mult\": 1.0},",
        "detail": "models.encoders.timm_mobilenetv3",
        "documentation": {}
    },
    {
        "label": "TimmUniversalEncoder",
        "kind": 6,
        "importPath": "models.encoders.timm_universal",
        "description": "models.encoders.timm_universal",
        "peekOfCode": "class TimmUniversalEncoder(nn.Module):\n    def __init__(self, name, pretrained=True, in_channels=3, depth=5, output_stride=32):\n        super().__init__()\n        kwargs = dict(\n            in_chans=in_channels,\n            features_only=True,\n            output_stride=output_stride,\n            pretrained=pretrained,\n            out_indices=tuple(range(depth)),\n        )",
        "detail": "models.encoders.timm_universal",
        "documentation": {}
    },
    {
        "label": "Covid",
        "kind": 6,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "class Covid(Dataset):\n    def __init__(self, rootpath, cropsize=(256, 256), mode=\"train\", *args, **kwargs):\n        super(Covid, self).__init__(*args, **kwargs)\n        assert mode in (\"train\", \"val\", \"test\")\n        self.mode = mode\n        self.cropsize = cropsize\n        self.rootpth = rootpath\n        self.imgs = []\n        class_dir = os.listdir(\n            os.path.join(self.rootpth, self.mode.capitalize())",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "AverageMeter",
        "kind": 6,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n    def update(self, val, n=1):\n        self.val = val",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "calculate_overlap_metrics",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def calculate_overlap_metrics(gt, pred, eps=1e-5):\n    output = pred.view(\n        -1,\n    )\n    target = gt.view(\n        -1,\n    ).float()\n    tp = torch.sum(output * target)  # TP\n    fp = torch.sum(output * (1 - target))  # FP\n    fn = torch.sum((1 - output) * target)  # FN",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "calculate_overlap_metrics_post",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def calculate_overlap_metrics_post(gt, pred,eps=1e-5):\n    output = pred.view(-1, )/255.\n    target = gt.view(-1, )/255.\n    tp = torch.sum(output * target)  # TP\n    fp = torch.sum(output * (1 - target))  # FP\n    fn = torch.sum((1 - output) * target)  # FN\n    tn = torch.sum((1 - output) * (1 - target))  # TN\n    pixel_acc = (tp + tn + eps) / (tp + tn + fp + fn + eps)\n    dice = (2 * tp + eps) / (2 * tp + fp + fn + eps)\n    iou = ( tp + eps) / ( tp + fp + fn + eps)",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "noise_remove",
        "kind": 2,
        "importPath": "utils.post_processing",
        "description": "utils.post_processing",
        "peekOfCode": "def noise_remove(im):\n    kernel = np.ones((5, 5), np.uint8)\n    im_re = cv2.morphologyEx(im, cv2.MORPH_CLOSE, kernel) \n    contours, hierarchy = cv2.findContours(im_re, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n# calculate points for each contour\n    for cnt in contours:\n        area = cv2.contourArea(cnt)\n        if area <10:\n            cv2.fillPoly(im_re, pts =[cnt], color=(0))\n    return im_re",
        "detail": "utils.post_processing",
        "documentation": {}
    },
    {
        "label": "post_processing",
        "kind": 2,
        "importPath": "utils.post_processing",
        "description": "utils.post_processing",
        "peekOfCode": "def post_processing(outputs_classification, output_lungs, output_infected):\n    output_infected = noise_remove(output_infected)\n    output_lungs = noise_remove(output_lungs)\n    output_infected = cv2.bitwise_and(output_infected,output_lungs, mask = None)\n    return outputs_classification, output_lungs, output_infected",
        "detail": "utils.post_processing",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument('--learning_rate', type=float, default=0.001)\nparser.add_argument('--num_epochs', type=int, default=200)\nparser.add_argument('--batch_size', type=int, default=16)\nparser.add_argument('--patience', type=int, default=300)\nparser.add_argument('--best_acc', type=int, default=0)\nparser.add_argument('--save_every', type=int, default=5)\nparser.add_argument('--alpha', type=int, default=1)\nargs = parser.parse_args()\nlearning_rate = args.learning_rate",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "args = parser.parse_args()\nlearning_rate = args.learning_rate\nnum_epochs = args.num_epochs\nbatch_size = args.batch_size\npatience = args.patience\nbest_acc = args.best_acc\nsave_every = args.save_every\nalpha = args.alpha\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "learning_rate",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "learning_rate = args.learning_rate\nnum_epochs = args.num_epochs\nbatch_size = args.batch_size\npatience = args.patience\nbest_acc = args.best_acc\nsave_every = args.save_every\nalpha = args.alpha\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device selected: \", device)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "num_epochs",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "num_epochs = args.num_epochs\nbatch_size = args.batch_size\npatience = args.patience\nbest_acc = args.best_acc\nsave_every = args.save_every\nalpha = args.alpha\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device selected: \", device)\n# Load config from JSON file",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "batch_size = args.batch_size\npatience = args.patience\nbest_acc = args.best_acc\nsave_every = args.save_every\nalpha = args.alpha\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device selected: \", device)\n# Load config from JSON file\nwith open(\"model_config.json\", \"r\") as f:",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "patience",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "patience = args.patience\nbest_acc = args.best_acc\nsave_every = args.save_every\nalpha = args.alpha\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device selected: \", device)\n# Load config from JSON file\nwith open(\"model_config.json\", \"r\") as f:\n    model_config = json.load(f)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "best_acc",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "best_acc = args.best_acc\nsave_every = args.save_every\nalpha = args.alpha\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device selected: \", device)\n# Load config from JSON file\nwith open(\"model_config.json\", \"r\") as f:\n    model_config = json.load(f)\ncustom_model = Model(**model_config)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "save_every",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "save_every = args.save_every\nalpha = args.alpha\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device selected: \", device)\n# Load config from JSON file\nwith open(\"model_config.json\", \"r\") as f:\n    model_config = json.load(f)\ncustom_model = Model(**model_config)\nmodel = custom_model.get_model()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "alpha",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "alpha = args.alpha\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device selected: \", device)\n# Load config from JSON file\nwith open(\"model_config.json\", \"r\") as f:\n    model_config = json.load(f)\ncustom_model = Model(**model_config)\nmodel = custom_model.get_model()\ntorch.cuda.empty_cache()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device selected: \", device)\n# Load config from JSON file\nwith open(\"model_config.json\", \"r\") as f:\n    model_config = json.load(f)\ncustom_model = Model(**model_config)\nmodel = custom_model.get_model()\ntorch.cuda.empty_cache()\ngc.collect()\nprint(model_config)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "custom_model",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "custom_model = Model(**model_config)\nmodel = custom_model.get_model()\ntorch.cuda.empty_cache()\ngc.collect()\nprint(model_config)\n################### Define Logging #####################\nlog_file = f'logs/training/alpha_{alpha}/{custom_model.encoder_name}_{custom_model.decoder_name}'\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(levelname)s - %(message)s',\n                    handlers=[",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "model = custom_model.get_model()\ntorch.cuda.empty_cache()\ngc.collect()\nprint(model_config)\n################### Define Logging #####################\nlog_file = f'logs/training/alpha_{alpha}/{custom_model.encoder_name}_{custom_model.decoder_name}'\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(levelname)s - %(message)s',\n                    handlers=[\n                        logging.StreamHandler(),  # Log to the console",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "log_file",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "log_file = f'logs/training/alpha_{alpha}/{custom_model.encoder_name}_{custom_model.decoder_name}'\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(levelname)s - %(message)s',\n                    handlers=[\n                        logging.StreamHandler(),  # Log to the console\n                        logging.FileHandler(log_file)  # Log to a file\n                    ])\n# Log the model information\nlogging.info(f'Model Information: \\n Encoder Name: {custom_model.encoder_name}, Decoder Name: {custom_model.decoder_name}')\n# Log the information",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "pixel_acc_infected_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "pixel_acc_infected_meter = AverageMeter()\ndice_infected_meter = AverageMeter()\niou_infected_meter = AverageMeter()\nprecision_infected_meter = AverageMeter()\nrecall_infected_meter = AverageMeter()\npixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "dice_infected_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "dice_infected_meter = AverageMeter()\niou_infected_meter = AverageMeter()\nprecision_infected_meter = AverageMeter()\nrecall_infected_meter = AverageMeter()\npixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "iou_infected_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "iou_infected_meter = AverageMeter()\nprecision_infected_meter = AverageMeter()\nrecall_infected_meter = AverageMeter()\npixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "precision_infected_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "precision_infected_meter = AverageMeter()\nrecall_infected_meter = AverageMeter()\npixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "recall_infected_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "recall_infected_meter = AverageMeter()\npixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# Set up data loaders",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "pixel_acc_lungs_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "pixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# Set up data loaders\ntrain_data = Covid(\"data/Infection Segmentation Data/Infection Segmentation Data\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "dice_lungs_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "dice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# Set up data loaders\ntrain_data = Covid(\"data/Infection Segmentation Data/Infection Segmentation Data\")\nval_data = Covid(",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "iou_lungs_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "iou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# Set up data loaders\ntrain_data = Covid(\"data/Infection Segmentation Data/Infection Segmentation Data\")\nval_data = Covid(\n    \"data/Infection Segmentation Data/Infection Segmentation Data\",",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "precision_lungs_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "precision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# Set up data loaders\ntrain_data = Covid(\"data/Infection Segmentation Data/Infection Segmentation Data\")\nval_data = Covid(\n    \"data/Infection Segmentation Data/Infection Segmentation Data\",\n    mode=\"val\",",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "recall_lungs_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "recall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# Set up data loaders\ntrain_data = Covid(\"data/Infection Segmentation Data/Infection Segmentation Data\")\nval_data = Covid(\n    \"data/Infection Segmentation Data/Infection Segmentation Data\",\n    mode=\"val\",\n)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "precision_classification_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "precision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# Set up data loaders\ntrain_data = Covid(\"data/Infection Segmentation Data/Infection Segmentation Data\")\nval_data = Covid(\n    \"data/Infection Segmentation Data/Infection Segmentation Data\",\n    mode=\"val\",\n)\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "recall_classification_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "recall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# Set up data loaders\ntrain_data = Covid(\"data/Infection Segmentation Data/Infection Segmentation Data\")\nval_data = Covid(\n    \"data/Infection Segmentation Data/Infection Segmentation Data\",\n    mode=\"val\",\n)\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "f1_score_classification_meter",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "f1_score_classification_meter = AverageMeter()\n# Set up data loaders\ntrain_data = Covid(\"data/Infection Segmentation Data/Infection Segmentation Data\")\nval_data = Covid(\n    \"data/Infection Segmentation Data/Infection Segmentation Data\",\n    mode=\"val\",\n)\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n# Set up model",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "train_data = Covid(\"data/Infection Segmentation Data/Infection Segmentation Data\")\nval_data = Covid(\n    \"data/Infection Segmentation Data/Infection Segmentation Data\",\n    mode=\"val\",\n)\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n# Set up model\nmodel = model.to(device)\n# Set up loss function",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "val_data",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "val_data = Covid(\n    \"data/Infection Segmentation Data/Infection Segmentation Data\",\n    mode=\"val\",\n)\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n# Set up model\nmodel = model.to(device)\n# Set up loss function\nclassification_loss_fn = nn.CrossEntropyLoss()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n# Set up model\nmodel = model.to(device)\n# Set up loss function\nclassification_loss_fn = nn.CrossEntropyLoss()\n# segmentation_loss_fn = torchvision.ops.sigmoid_focal_loss\nsegmentation_loss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "val_loader",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n# Set up model\nmodel = model.to(device)\n# Set up loss function\nclassification_loss_fn = nn.CrossEntropyLoss()\n# segmentation_loss_fn = torchvision.ops.sigmoid_focal_loss\nsegmentation_loss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\")\n# Set up training loop",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "model = model.to(device)\n# Set up loss function\nclassification_loss_fn = nn.CrossEntropyLoss()\n# segmentation_loss_fn = torchvision.ops.sigmoid_focal_loss\nsegmentation_loss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\")\n# Set up training loop\nfor epoch in range(num_epochs):\n    model.train()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "classification_loss_fn",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "classification_loss_fn = nn.CrossEntropyLoss()\n# segmentation_loss_fn = torchvision.ops.sigmoid_focal_loss\nsegmentation_loss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\")\n# Set up training loop\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    print(f\">>> Training epoch {epoch}\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "segmentation_loss_fn",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "segmentation_loss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\")\n# Set up training loop\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    print(f\">>> Training epoch {epoch}\")\n    progress = tqdm(train_loader, total=int(len(train_loader)))\n    for batch_idx, (",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\")\n# Set up training loop\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    print(f\">>> Training epoch {epoch}\")\n    progress = tqdm(train_loader, total=int(len(train_loader)))\n    for batch_idx, (\n        inputs,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "scheduler",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\")\n# Set up training loop\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    print(f\">>> Training epoch {epoch}\")\n    progress = tqdm(train_loader, total=int(len(train_loader)))\n    for batch_idx, (\n        inputs,\n        labels_classification,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "Model",
        "kind": 6,
        "importPath": "model",
        "description": "model",
        "peekOfCode": "class Model:\n    def __init__(\n        self,\n        encoder_name=\"resnet50\",\n        decoder_name=\"unet\",\n        classes=3,\n        pooling=\"avg\",\n        dropout=0.5,\n        encoder_weights=None,\n        in_channels=3,",
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device selected: ',device)\nparser = argparse.ArgumentParser()\nparser.add_argument('--weight_name', type=str, default='epoch_199.ckpt')\nargs = parser.parse_args()\nweight_name = args.weight_name\n# Load config from JSON file\nwith open(\"test_model_config.json\", \"r\") as f:\n    model_config = json.load(f)\ncustom_model = Model(**model_config)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument('--weight_name', type=str, default='epoch_199.ckpt')\nargs = parser.parse_args()\nweight_name = args.weight_name\n# Load config from JSON file\nwith open(\"test_model_config.json\", \"r\") as f:\n    model_config = json.load(f)\ncustom_model = Model(**model_config)\nmodel = custom_model.get_model()\nmodel = model.to(device)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "args = parser.parse_args()\nweight_name = args.weight_name\n# Load config from JSON file\nwith open(\"test_model_config.json\", \"r\") as f:\n    model_config = json.load(f)\ncustom_model = Model(**model_config)\nmodel = custom_model.get_model()\nmodel = model.to(device)\ntorch.cuda.empty_cache()\ngc.collect()",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "weight_name",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "weight_name = args.weight_name\n# Load config from JSON file\nwith open(\"test_model_config.json\", \"r\") as f:\n    model_config = json.load(f)\ncustom_model = Model(**model_config)\nmodel = custom_model.get_model()\nmodel = model.to(device)\ntorch.cuda.empty_cache()\ngc.collect()\nweight_file = f\"checkpoints/alpha_1/{custom_model.encoder_name}_{custom_model.decoder_name}/{weight_name}\"",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "custom_model",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "custom_model = Model(**model_config)\nmodel = custom_model.get_model()\nmodel = model.to(device)\ntorch.cuda.empty_cache()\ngc.collect()\nweight_file = f\"checkpoints/alpha_1/{custom_model.encoder_name}_{custom_model.decoder_name}/{weight_name}\"\nmodel.load_state_dict(torch.load(weight_file,map_location=device))\nmodel.eval()\n################### Define Logging #####################\nlog_file = f'logs/testing/alpha_1/{custom_model.encoder_name}_{custom_model.decoder_name}'",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "model = custom_model.get_model()\nmodel = model.to(device)\ntorch.cuda.empty_cache()\ngc.collect()\nweight_file = f\"checkpoints/alpha_1/{custom_model.encoder_name}_{custom_model.decoder_name}/{weight_name}\"\nmodel.load_state_dict(torch.load(weight_file,map_location=device))\nmodel.eval()\n################### Define Logging #####################\nlog_file = f'logs/testing/alpha_1/{custom_model.encoder_name}_{custom_model.decoder_name}'\nlogging.basicConfig(level=logging.INFO,",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "model = model.to(device)\ntorch.cuda.empty_cache()\ngc.collect()\nweight_file = f\"checkpoints/alpha_1/{custom_model.encoder_name}_{custom_model.decoder_name}/{weight_name}\"\nmodel.load_state_dict(torch.load(weight_file,map_location=device))\nmodel.eval()\n################### Define Logging #####################\nlog_file = f'logs/testing/alpha_1/{custom_model.encoder_name}_{custom_model.decoder_name}'\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(levelname)s - %(message)s',",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "weight_file",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "weight_file = f\"checkpoints/alpha_1/{custom_model.encoder_name}_{custom_model.decoder_name}/{weight_name}\"\nmodel.load_state_dict(torch.load(weight_file,map_location=device))\nmodel.eval()\n################### Define Logging #####################\nlog_file = f'logs/testing/alpha_1/{custom_model.encoder_name}_{custom_model.decoder_name}'\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(levelname)s - %(message)s',\n                    handlers=[\n                        logging.StreamHandler(),  # Log to the console\n                        logging.FileHandler(log_file)  # Log to a file",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "log_file",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "log_file = f'logs/testing/alpha_1/{custom_model.encoder_name}_{custom_model.decoder_name}'\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(levelname)s - %(message)s',\n                    handlers=[\n                        logging.StreamHandler(),  # Log to the console\n                        logging.FileHandler(log_file)  # Log to a file\n                    ])\n# Log the information\nlogging.info(f'Used Weight File: {weight_file}')\n############ Define Metric ###############",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "pixel_acc_infected_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "pixel_acc_infected_meter = AverageMeter()\ndice_infected_meter = AverageMeter()\niou_infected_meter = AverageMeter()\nprecision_infected_meter = AverageMeter()\nrecall_infected_meter = AverageMeter()\npixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "dice_infected_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "dice_infected_meter = AverageMeter()\niou_infected_meter = AverageMeter()\nprecision_infected_meter = AverageMeter()\nrecall_infected_meter = AverageMeter()\npixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "iou_infected_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "iou_infected_meter = AverageMeter()\nprecision_infected_meter = AverageMeter()\nrecall_infected_meter = AverageMeter()\npixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "precision_infected_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "precision_infected_meter = AverageMeter()\nrecall_infected_meter = AverageMeter()\npixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "recall_infected_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "recall_infected_meter = AverageMeter()\npixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# # Set up data loaders",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "pixel_acc_lungs_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "pixel_acc_lungs_meter = AverageMeter()\ndice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# # Set up data loaders\ntest_data = Covid('data/Infection Segmentation Data/Infection Segmentation Data',mode='test' )",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "dice_lungs_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "dice_lungs_meter = AverageMeter()\niou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# # Set up data loaders\ntest_data = Covid('data/Infection Segmentation Data/Infection Segmentation Data',mode='test' )\nval_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=2)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "iou_lungs_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "iou_lungs_meter = AverageMeter()\nprecision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# # Set up data loaders\ntest_data = Covid('data/Infection Segmentation Data/Infection Segmentation Data',mode='test' )\nval_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=2)\nfor batch_idx, (inputs, labels_classification,  labels_segmentation_lungs, labels_segmentation_infected) in enumerate(val_loader):",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "precision_lungs_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "precision_lungs_meter = AverageMeter()\nrecall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# # Set up data loaders\ntest_data = Covid('data/Infection Segmentation Data/Infection Segmentation Data',mode='test' )\nval_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=2)\nfor batch_idx, (inputs, labels_classification,  labels_segmentation_lungs, labels_segmentation_infected) in enumerate(val_loader):\n         # To device",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "recall_lungs_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "recall_lungs_meter = AverageMeter()\nprecision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# # Set up data loaders\ntest_data = Covid('data/Infection Segmentation Data/Infection Segmentation Data',mode='test' )\nval_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=2)\nfor batch_idx, (inputs, labels_classification,  labels_segmentation_lungs, labels_segmentation_infected) in enumerate(val_loader):\n         # To device\n            inputs = inputs.to(device)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "precision_classification_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "precision_classification_meter = AverageMeter()\nrecall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# # Set up data loaders\ntest_data = Covid('data/Infection Segmentation Data/Infection Segmentation Data',mode='test' )\nval_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=2)\nfor batch_idx, (inputs, labels_classification,  labels_segmentation_lungs, labels_segmentation_infected) in enumerate(val_loader):\n         # To device\n            inputs = inputs.to(device)\n            labels_classification = labels_classification.to(device)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "recall_classification_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "recall_classification_meter = AverageMeter()\nf1_score_classification_meter = AverageMeter()\n# # Set up data loaders\ntest_data = Covid('data/Infection Segmentation Data/Infection Segmentation Data',mode='test' )\nval_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=2)\nfor batch_idx, (inputs, labels_classification,  labels_segmentation_lungs, labels_segmentation_infected) in enumerate(val_loader):\n         # To device\n            inputs = inputs.to(device)\n            labels_classification = labels_classification.to(device)\n            labels_segmentation_infected = labels_segmentation_infected.to(device)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "f1_score_classification_meter",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "f1_score_classification_meter = AverageMeter()\n# # Set up data loaders\ntest_data = Covid('data/Infection Segmentation Data/Infection Segmentation Data',mode='test' )\nval_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=2)\nfor batch_idx, (inputs, labels_classification,  labels_segmentation_lungs, labels_segmentation_infected) in enumerate(val_loader):\n         # To device\n            inputs = inputs.to(device)\n            labels_classification = labels_classification.to(device)\n            labels_segmentation_infected = labels_segmentation_infected.to(device)\n            labels_segmentation_lungs = labels_segmentation_lungs.to(device)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "test_data",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "test_data = Covid('data/Infection Segmentation Data/Infection Segmentation Data',mode='test' )\nval_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=2)\nfor batch_idx, (inputs, labels_classification,  labels_segmentation_lungs, labels_segmentation_infected) in enumerate(val_loader):\n         # To device\n            inputs = inputs.to(device)\n            labels_classification = labels_classification.to(device)\n            labels_segmentation_infected = labels_segmentation_infected.to(device)\n            labels_segmentation_lungs = labels_segmentation_lungs.to(device)\n            outputs_classification, outputs_segmentation_lungs, outputs_segmentation_infected = model(inputs)\n            outputs_classification = outputs_classification.type(torch.float32)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "val_loader",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "val_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=2)\nfor batch_idx, (inputs, labels_classification,  labels_segmentation_lungs, labels_segmentation_infected) in enumerate(val_loader):\n         # To device\n            inputs = inputs.to(device)\n            labels_classification = labels_classification.to(device)\n            labels_segmentation_infected = labels_segmentation_infected.to(device)\n            labels_segmentation_lungs = labels_segmentation_lungs.to(device)\n            outputs_classification, outputs_segmentation_lungs, outputs_segmentation_infected = model(inputs)\n            outputs_classification = outputs_classification.type(torch.float32)\n            outputs_segmentation_infected = outputs_segmentation_infected.type(torch.float32)",
        "detail": "test",
        "documentation": {}
    }
]